{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №7. RNN\n",
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 40\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "EPS = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция очистки файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input = \"testText.txt\"\n",
    "import codecs\n",
    "def clear_file(input):\n",
    "    def isCorrectChar(c):\n",
    "        return c.isspace() or c == '”' or c == '\\'' or (c.isalpha() and (c not in allowed))\n",
    "\n",
    "    allowed = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "               'v', 'w', 'x', 'y', 'z', 'ê', 'ê', 'ê']\n",
    "    inputFile = os.path.join(\"results\", f'{input}.txt')\n",
    "    outputFile = os.path.join(\"results\", f'___clear___{input}.txt')\n",
    "\n",
    "    if os.path.exists(outputFile):\n",
    "        print(f'WARNING: {outputFile} is exist!!!', flush=True)\n",
    "        return outputFile\n",
    "\n",
    "    print(f'opening on clearing file {inputFile}', flush=True)\n",
    "    # text = open(inputFile).read()\n",
    "    data = codecs.open( inputFile, \"r\", \"utf-8\" )\n",
    "    text = data.read()\n",
    "    data .close()\n",
    "    text = text.lower()\n",
    "    text = \"\".join(list(filter(isCorrectChar, text)))\n",
    "    text = re.sub('\\n+', '\\n', re.sub('\\n ', '\\n', re.sub(' +', ' ', text)))\n",
    "\n",
    "    print(f'writing cleared file {outputFile}', flush=True)\n",
    "    open(outputFile, \"w\").write(text)\n",
    "\n",
    "    return outputFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция инициализации данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_data(file):\n",
    "    raw_text = open(file).read()\n",
    "\n",
    "    chars = sorted(list(set(raw_text)))\n",
    "    chars_int_map = dict((c, i) for i, c in enumerate(chars))\n",
    "    int_chars_map = dict((i, c) for i, c in enumerate(chars))\n",
    "    amount_chars, amount_different_chars = len(raw_text), len(chars)\n",
    "\n",
    "    x_arr_dataset_custom_tmp, y_arr_dataset_custom_tmp = [], []\n",
    "    for i in range(amount_chars - SEQUENCE_LENGTH):\n",
    "        sequence_from, char_out = raw_text[i:i + SEQUENCE_LENGTH], raw_text[i + SEQUENCE_LENGTH]\n",
    "        x_arr_tmp = list(map(lambda char: chars_int_map[char], sequence_from))\n",
    "        x_arr_dataset_custom_tmp.append(x_arr_tmp)\n",
    "        y_arr_dataset_custom_tmp.append(chars_int_map[char_out])\n",
    "\n",
    "    x_arr_dataset = numpy.reshape(x_arr_dataset_custom_tmp, (len(x_arr_dataset_custom_tmp), SEQUENCE_LENGTH, 1))\n",
    "    x_arr_dataset = x_arr_dataset / float(amount_different_chars)\n",
    "    # One-hot преобразование:\n",
    "    y_arr_dataset = np_utils.to_categorical(y_arr_dataset_custom_tmp)\n",
    "\n",
    "    return x_arr_dataset, y_arr_dataset, x_arr_dataset_custom_tmp, int_chars_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция инициализации модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(x_arr_dataset, y_arr_dataset):\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(x_arr_dataset.shape[1], x_arr_dataset.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(y_arr_dataset.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach_model(file, teached_model_folder):\n",
    "    print(\"Start teaching model\", flush=True)\n",
    "\n",
    "    x_arr_dataset, y_arr_dataset, _, _ = init_data(file)\n",
    "\n",
    "    model = init_model(x_arr_dataset, y_arr_dataset)\n",
    "\n",
    "    filepath = f'results/{teached_model_folder}/' + \"epoch_{epoch:02d}__loss_{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(x_arr_dataset, y_arr_dataset, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks_list)\n",
    "    print(\"End teaching model\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция генерации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_RNN(file, teached_model_file_path, amount_sequence=100):\n",
    "    print(f'Start generating text under teached model on {teached_model_file_path}', flush=True)\n",
    "\n",
    "    x_arr_dataset, y_arr_dataset, x_arr_dataset_custom_tmp, int_chars_map = init_data(file)\n",
    "    amount_different_chars = len(int_chars_map)\n",
    "\n",
    "    model = init_model(x_arr_dataset, y_arr_dataset)\n",
    "    model.load_weights(teached_model_file_path)\n",
    "\n",
    "    start_sequence_id = numpy.random.randint(0, len(x_arr_dataset_custom_tmp) - 1)\n",
    "    start_sequence = x_arr_dataset_custom_tmp[start_sequence_id]\n",
    "    sequence_from = \"\".join([int_chars_map[value] for value in start_sequence])\n",
    "    print(f'Start phrase:\\n{sequence_from}', flush=True)\n",
    "    print(\"Generating:\", flush=True)\n",
    "    for i in range(amount_sequence):\n",
    "        x = numpy.reshape(start_sequence, (1, len(start_sequence), 1))\n",
    "        x = x / float(amount_different_chars)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_chars_map[index]\n",
    "        sys.stdout.write(result)\n",
    "        start_sequence.append(index)\n",
    "        start_sequence = start_sequence[1:len(start_sequence)]\n",
    "    print(f'\\nEnd generating text', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция предсказания с помощью марковской цепи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mark(file, n, k, m):\n",
    "    print(f'Start generating text for {file}', flush=True)\n",
    "    text = open(file).read()\n",
    "    windows = get_windows(text, n)\n",
    "    graph, w_to_int, int_to_w = get_graph(windows, text, n)\n",
    "    start_line = get_random_start(text)\n",
    "    generating_by_graph(n, k, m, start_line, graph, w_to_int, int_to_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(text, n):\n",
    "    windows = set()\n",
    "    for i in range(len(text) - n + 1):\n",
    "        windows.add(text[i:i + n])\n",
    "    print(f'Windows: {len(windows)}', flush=True)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция получения матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(windows, text, n):\n",
    "    window_to_int = dict((c, i) for i, c in enumerate(windows))\n",
    "    int_to_wwindow = dict((i, c) for i, c in enumerate(windows))\n",
    "    matrix = [[0 for _ in range(len(windows))] for _ in range(len(windows))]\n",
    "    for i in range(len(text) - n):\n",
    "        cur_w = text[i:i + n]\n",
    "        next_w = text[(i + 1):(i + n + 1)]\n",
    "        matrix[window_to_int[cur_w]][window_to_int[next_w]] += 1\n",
    "    matrix = np.array(norm_matrix(matrix))\n",
    "    return matrix, window_to_int, int_to_wwindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция случайного начала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_start(text):\n",
    "    lines = text.split('\\n')\n",
    "    start = np.random.randint(0, len(lines) - 1)\n",
    "    return lines[start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция генерации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K have to more M\n",
    "def generating_by_graph(n, k, m, start_line, matrix, w_to_int, int_to_w):\n",
    "    prefix = start_line[0:k]\n",
    "    print(f'Start phrase:\\n{prefix}', flush=True)\n",
    "    print(\"Generating:\", flush=True)\n",
    "    start_window = prefix[len(prefix) - n:]\n",
    "    for i in range(m):\n",
    "        sug_next_pos = get_all_by_max(matrix[w_to_int[start_window]])\n",
    "        if len(sug_next_pos) == 0:\n",
    "            print(f'Can\\'t continue', flush=True)\n",
    "            break\n",
    "        elif len(sug_next_pos) == 1:\n",
    "            ind = 0\n",
    "        else:\n",
    "            ind = np.random.randint(0, len(sug_next_pos) - 1)\n",
    "        next_pos = sug_next_pos[ind]\n",
    "        start_window = int_to_w[next_pos]\n",
    "        sys.stdout.write(start_window[len(start_window) - 1])\n",
    "    print('\\nEnd generating text', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция получения максимума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_by_max(data):\n",
    "    max_v = max(data)\n",
    "    res = []\n",
    "    for i in range(len(data)):\n",
    "        if abs(data[i] - max_v) < EPS:\n",
    "            res.append(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция нормализованной матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_matrix(matrix):\n",
    "    new_matrix = []\n",
    "    for row in matrix:\n",
    "        sum_v = sum(row)\n",
    "        if sum_v != 0:\n",
    "            new_row = list(map(lambda x: x / sum_v, row))\n",
    "            new_matrix.append(new_row)\n",
    "        else:\n",
    "            new_matrix.append(row)\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening on clearing file results\\evgeny_onegin.txt\n",
      "writing cleared file results\\___clear___evgeny_onegin.txt\n",
      "Start teaching model\n",
      "Epoch 1/30\n",
      "131949/131949 [==============================] - 185s 1ms/step - loss: 3.0930\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.09295, saving model to results/evgeny/epoch_01__loss_3.0930.hdf5\n",
      "Epoch 2/30\n",
      "131949/131949 [==============================] - 187s 1ms/step - loss: 3.0134\n",
      "\n",
      "Epoch 00002: loss improved from 3.09295 to 3.01336, saving model to results/evgeny/epoch_02__loss_3.0134.hdf5\n",
      "Epoch 3/30\n",
      "131949/131949 [==============================] - 181s 1ms/step - loss: 2.9641 1s  - ETA: 0s - loss: 2.96\n",
      "\n",
      "Epoch 00003: loss improved from 3.01336 to 2.96410, saving model to results/evgeny/epoch_03__loss_2.9641.hdf5\n",
      "Epoch 4/30\n",
      "131949/131949 [==============================] - 181s 1ms/step - loss: 2.9166\n",
      "\n",
      "Epoch 00004: loss improved from 2.96410 to 2.91658, saving model to results/evgeny/epoch_04__loss_2.9166.hdf5\n",
      "Epoch 5/30\n",
      "131949/131949 [==============================] - 181s 1ms/step - loss: 2.8777\n",
      "\n",
      "Epoch 00005: loss improved from 2.91658 to 2.87769, saving model to results/evgeny/epoch_05__loss_2.8777.hdf5\n",
      "Epoch 6/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.8566\n",
      "\n",
      "Epoch 00006: loss improved from 2.87769 to 2.85659, saving model to results/evgeny/epoch_06__loss_2.8566.hdf5\n",
      "Epoch 7/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.8400 0s - loss: 2.83\n",
      "\n",
      "Epoch 00007: loss improved from 2.85659 to 2.83996, saving model to results/evgeny/epoch_07__loss_2.8400.hdf5\n",
      "Epoch 8/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.8248\n",
      "\n",
      "Epoch 00008: loss improved from 2.83996 to 2.82476, saving model to results/evgeny/epoch_08__loss_2.8248.hdf5\n",
      "Epoch 9/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.8196\n",
      "\n",
      "Epoch 00009: loss improved from 2.82476 to 2.81962, saving model to results/evgeny/epoch_09__loss_2.8196.hdf5\n",
      "Epoch 10/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.7951\n",
      "\n",
      "Epoch 00010: loss improved from 2.81962 to 2.79506, saving model to results/evgeny/epoch_10__loss_2.7951.hdf5\n",
      "Epoch 11/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.7782\n",
      "\n",
      "Epoch 00011: loss improved from 2.79506 to 2.77821, saving model to results/evgeny/epoch_11__loss_2.7782.hdf5\n",
      "Epoch 12/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.7633\n",
      "\n",
      "Epoch 00012: loss improved from 2.77821 to 2.76332, saving model to results/evgeny/epoch_12__loss_2.7633.hdf5\n",
      "Epoch 13/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.7481\n",
      "\n",
      "Epoch 00013: loss improved from 2.76332 to 2.74812, saving model to results/evgeny/epoch_13__loss_2.7481.hdf5\n",
      "Epoch 14/30\n",
      "131949/131949 [==============================] - 177s 1ms/step - loss: 2.7306\n",
      "\n",
      "Epoch 00014: loss improved from 2.74812 to 2.73057, saving model to results/evgeny/epoch_14__loss_2.7306.hdf5\n",
      "Epoch 15/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.7154\n",
      "\n",
      "Epoch 00015: loss improved from 2.73057 to 2.71540, saving model to results/evgeny/epoch_15__loss_2.7154.hdf5\n",
      "Epoch 16/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.6993\n",
      "\n",
      "Epoch 00016: loss improved from 2.71540 to 2.69931, saving model to results/evgeny/epoch_16__loss_2.6993.hdf5\n",
      "Epoch 17/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.6812\n",
      "\n",
      "Epoch 00017: loss improved from 2.69931 to 2.68118, saving model to results/evgeny/epoch_17__loss_2.6812.hdf5\n",
      "Epoch 18/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.6672 1s\n",
      "\n",
      "Epoch 00018: loss improved from 2.68118 to 2.66722, saving model to results/evgeny/epoch_18__loss_2.6672.hdf5\n",
      "Epoch 19/30\n",
      "131949/131949 [==============================] - 180s 1ms/step - loss: 2.6506\n",
      "\n",
      "Epoch 00019: loss improved from 2.66722 to 2.65061, saving model to results/evgeny/epoch_19__loss_2.6506.hdf5\n",
      "Epoch 20/30\n",
      "131949/131949 [==============================] - 173s 1ms/step - loss: 2.6339\n",
      "\n",
      "Epoch 00020: loss improved from 2.65061 to 2.63391, saving model to results/evgeny/epoch_20__loss_2.6339.hdf5\n",
      "Epoch 21/30\n",
      "131949/131949 [==============================] - 171s 1ms/step - loss: 2.6170\n",
      "\n",
      "Epoch 00021: loss improved from 2.63391 to 2.61703, saving model to results/evgeny/epoch_21__loss_2.6170.hdf5\n",
      "Epoch 22/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.5987\n",
      "\n",
      "Epoch 00022: loss improved from 2.61703 to 2.59874, saving model to results/evgeny/epoch_22__loss_2.5987.hdf5\n",
      "Epoch 23/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.5827\n",
      "\n",
      "Epoch 00023: loss improved from 2.59874 to 2.58271, saving model to results/evgeny/epoch_23__loss_2.5827.hdf5\n",
      "Epoch 24/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.5642\n",
      "\n",
      "Epoch 00024: loss improved from 2.58271 to 2.56416, saving model to results/evgeny/epoch_24__loss_2.5642.hdf5\n",
      "Epoch 25/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.5442\n",
      "\n",
      "Epoch 00025: loss improved from 2.56416 to 2.54415, saving model to results/evgeny/epoch_25__loss_2.5442.hdf5\n",
      "Epoch 26/30\n",
      "131949/131949 [==============================] - 171s 1ms/step - loss: 2.5259\n",
      "\n",
      "Epoch 00026: loss improved from 2.54415 to 2.52592, saving model to results/evgeny/epoch_26__loss_2.5259.hdf5\n",
      "Epoch 27/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.5052\n",
      "\n",
      "Epoch 00027: loss improved from 2.52592 to 2.50524, saving model to results/evgeny/epoch_27__loss_2.5052.hdf5\n",
      "Epoch 28/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.4877\n",
      "\n",
      "Epoch 00028: loss improved from 2.50524 to 2.48766, saving model to results/evgeny/epoch_28__loss_2.4877.hdf5\n",
      "Epoch 29/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.4710\n",
      "\n",
      "Epoch 00029: loss improved from 2.48766 to 2.47099, saving model to results/evgeny/epoch_29__loss_2.4710.hdf5\n",
      "Epoch 30/30\n",
      "131949/131949 [==============================] - 170s 1ms/step - loss: 2.4519\n",
      "\n",
      "Epoch 00030: loss improved from 2.47099 to 2.45188, saving model to results/evgeny/epoch_30__loss_2.4519.hdf5\n",
      "End teaching model\n"
     ]
    }
   ],
   "source": [
    "raw_file = \"evgeny_onegin\"\n",
    "teached_model_folder = \"evgeny\"\n",
    "teached_model = \"epoch_30__loss_2.4397.hdf5\"\n",
    "teached_model_file_path = f'results/{teached_model_folder}/{teached_model}'\n",
    "cleared_file = clear_file(raw_file)\n",
    "teach_model(cleared_file, teached_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating text under teached model on results/evgeny/epoch_30__loss_2.4397.hdf5\n",
      "Start phrase:\n",
      "й\n",
      "ужели он так точно он\n",
      "давно ли к нам о\n",
      "Generating:\n",
      "о соанеть\n",
      "и вое в семе сердце воед\n",
      "по все д гы верее не воеда\n",
      "соава поиная в сомо ное\n",
      "пои не поитали поина\n",
      "и вое вереен в семей сений\n",
      "и вое в семе сердце воед\n",
      "и вое в семе сердце воед\n",
      "по все д гы верее не воеда\n",
      "соава поиная в сомо ное\n",
      "пои н\n",
      "End generating text\n"
     ]
    }
   ],
   "source": [
    "teached_model = \"epoch_30__loss_2.4519.hdf5\"\n",
    "generate_text_RNN(cleared_file, teached_model_file_path, amount_sequence=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating text for results/___clear___evgeny_onegin.txt\n",
      "Windows:  26901\n",
      "Start phrase:\n",
      "и я в зако\n",
      "Generating:\n",
      "н себе вменяя\n",
      "страстей единый произвол\n",
      "с толпою чувства разделяя\n",
      "я музу резвую привел\n",
      "на шум пиры\n",
      "она несла свои дары\n",
      "и как вакханочка резвую привел\n",
      "на шум пиры\n",
      "она несла свои дары\n",
      "и как вакханочка ре\n",
      "End generating text\n"
     ]
    }
   ],
   "source": [
    "do_mark(cleared_file, 4, 10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
