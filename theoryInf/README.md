# Работа в рамках дисциплины "Современная теория информации".

***Кодирование данных. Создание архиватора/деархиватора.***

Необходимо было реализовать методами программирования кодер и декодер на любом из языков программирования.  В качестве параметра на вход кодера подается имя сжимаемого файла и имя файла, которое
должно быть на выходе из кодера, программа же выдает файл со сжатыми данными. В качестве параметра на вход декодера подается имя файла со сжатыми файлами, а также имя декодированного файла. На 
выходе декодер выдает файл, идентичный исходному, поданному кодеру.

В качестве алгоритма сжатия был выбран **метод сжатия алгоритмом Хаффмана**. Перед сжатием данные обрабатываются – для преобразования используются обратимые алгоритмы: **алгоритм Бэрроуза-Уиллера**, а 
затем – **методом “Стопка книг”**.

**Преобразование Бэрроуза-Уиллера**

Принцип данного преобразования: первый шаг – выделение данных. Далее, нужно из полученного блока данных создать матрицу всех возможных его циклических перестановок. Первой строкой матрицы будет 
исходная последовательность, второй строкой – она же, сдвинутая циклически на один символ влево и так далее. Далее пометим в этой матрице исходную строку и отсортируем все строки в соответствии 
с лексикографическим порядком символов. Будем считать, что одна строка должна находиться в матрице выше другой в том случае, если в самой левой из позиций, начиная с которой строки отличаются, 
в этой строке находится символ лексикографически меньший, чем у другой строки. Таким образом, следует отсортировать строки сначала по первому символу, затем строки, у которых первые символы 
равны – по второму и так далее. Последний шаг – выписать символы последнего столбца и запомнить номер исходной строки среди отсортированных.

Данное преобразование не даст никакого результата, если после него сразу применить алгоритм Хаффмана или любой другой алгоритм сжатия, но если после преобразования Бэрроуза-Уиллера применить метод “Стопка книг”, то полученный набор чисел будет 
иметь крайне удачное статистическое распределение для применения сжатия Хаффмана. 

В реализованном мною преобразовании изначальный объем данных делится на блоки для экономии времени и памяти. Чтобы найти границы данных блоков в декорируемом файле, мною были добавлены 
соответствующие символы-метки. 

Алгоритм был оптимизирован и работает за $О(N\ log\ N)$. Также подразумевается, что алгоритм должен использовать О(N) памяти, но ввиду не идеальности кода затрачивается $O(N^2)$ памяти.

**Метод “Стопка книг”**

Данный метод работает следующим образом. Изначально каждое возможное значение байта записывается в список, так называемый алфавит, в ячейку с номером. В процессе обработки данных этот список 
изменяется. По мере поступления очередного символа на выход подается номер элемента, содержащего его значение. После чего этот символ перемещается в начало списка, смещая остальные элементы 
вправо. А на выходе алгоритм выдает то значение, на которое необходимо было сместить символ в алфавите, то есть то количество различных переменных, которое находится между данным символом и 
им же, использованным ранее в данных или алфавите. В результате работы данного алгоритма получается последовательность из цифр. Рассмотрим пример:

Пусть алфавит источника $A=$ { $a,b,c,d,e$ } и генерируется сообщение $baadaade...$ . Пример того, как меняется порядок букв и какие числа формируются по мере поступления символов от 
источника, представлен в таблице 1.

**Таблица 1. Пример работы метода “Стопка книг”:**

| Сообщние                    | b | a | a | d | a | a | d | e |
|-----------------------------|---|---|---|---|---|---|---|---|
| Позиция буквы в алфавите: 0 | a | b | a | a | d | a | a | d |
| Позиция буквы в алфавите: 1 | b | a | b | b | a | d | d | a |
| Позиция буквы в алфавите: 2 | c | c | c | c | b | b | b | b |
| Позиция буквы в алфавите: 3 | d | d | d | d | c | c | c | c |
| Позиция буквы в алфавите: 4 | e | e | e | e | e | e | e | e |
| Код                         | 1 | 1 | 0 | 3 | 1 | 0 | 1 | 4 |

Таким образом, вывод: 1 1 0 3 1 0 1 4.

**Сжатие алгоритмом Хаффмана**

Идея алгоритма состоит в следующем: зная вероятности появления символов в сообщении, можно описать процедуру построения кодов переменной длины, состоящих из целого количества битов. 
Символам с большей вероятностью ставятся в соответствие более короткие коды. Коды Хаффмана обладают свойством префиксности (то есть ни одно кодовое слово не является префиксом другого), 
что позволяет однозначно их декодировать. 

Классический алгоритм Хаффмана на входе получает таблицу частот встречаемости символов в сообщении. Далее на основании этой таблицы строится дерево кодирования Хаффмана.

1.	Символы входного алфавита образуют список свободных узлов. Каждый лист имеет вес, который может быть равен либо вероятности, либо количеству вхождений символа в сжимаемое сообщение.
2.	Выбираются два свободных узла дерева с наименьшими весами.
3.	Создается их родитель с весом, равным их суммарному весу.
4.	Родитель добавляется в список свободных узлов, а два его потомка удаляются из этого списка.
5.	Одной дуге, выходящей из родителя, ставится в соответствие бит 1, другой — бит 0. Битовые значения ветвей, исходящих от корня, не зависят от весов потомков.
6.	Шаги, начиная со второго, повторяются до тех пор, пока в списке свободных узлов не останется только один свободный узел. Он и будет считаться корнем дерева.

В данной работе кодовая таблица сохранялась в файл с кодированными данными.

